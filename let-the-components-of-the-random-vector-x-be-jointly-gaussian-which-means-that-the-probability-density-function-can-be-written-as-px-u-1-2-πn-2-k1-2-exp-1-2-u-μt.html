<!DOCTYPE html>
    <html lang="en">
    
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-PQPWWZGD1B"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-PQPWWZGD1B');
        </script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7833742603914548"
     crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous">
        <link rel="stylesheet" href="/assets/css/min/@ui.css">
        <link rel="shortcut icon" href="/assets/images/favicons/favicon.ico">
        <link rel="apple-touch-icon-precomposed" href="/assets/images/favicons/apple-touch-icon-152x152-precomposed.png">
        <link rel="apple-touch-icon" sizes="180x180" href="/assets/images/favicons/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/assets/images/favicons/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/assets/images/favicons/favicon-16x16.png">
        <link rel="manifest" href="/assets/images/favicons/site.webmanifest">
        <link rel="mask-icon" href="/assets/images/favicons/safari-pinned-tab.svg" color="#10106d">
        <meta name="msapplication-TileColor" content="#10106d">
        <meta name="msapplication-config" content="/assets/images/favicons/browserconfig.xml">
        <meta name="theme-color" content="#10106d">
        <link rel="canonical" href="https://vlavar.com/engineeringdb/let-the-components-of-the-random-vector-x-be-jointly-gaussian-which-means-that-the-probability-density-function-can-be-written-as-px-u-1-2-%CF%80n-2-k1-2-exp-1-2-u-%CE%BCt" />
        <meta property="og:locale" content="en_US" />
        <meta property="og:type" content="article" />
        <meta property="og:site_name" content="Vlavar" />
        <meta property="article:publisher" content="admin@vlavar" />
       <title>Let the components of the random vector X be jointly Gaussian, which means that the probability density function can be written as pX (u) = 1 / (2 π)^n/2 |K|^1/2 exp (- 1/2 (u – μ)^T K^-1 (u - μ) in which μ is a vector of constants; K is a square, symmetric, positive-definite matrix of constants; [solved] | Vlavar Engineering</title>
<meta property="og:title" content="Let the components of the random vector X be jointly Gaussian, which means that the probability density function can be written as pX (u) = 1 / (2 π)^n/2 |K|^1/2 exp (- 1/2 (u – μ)^T K^-1 (u - μ) in which μ is a vector of constants; K is a square, symmetric, positive-definite matrix of constants;[solved!] | Vlavar Engineering" />
<meta name="description" content="First note that the exponent in  p_{vec{X}}(vec{u}) is a quadratic form in all the u_{j}  terms, making this joint"/>
<meta property="og:description" content="First note that the exponent in  p_{vec{X}}(vec{u}) is a quadratic form in all the u_{j}  terms, making this joint" />

<meta property="og:updated_time" content="2022-12-05T22:19:40+04:00" />
<meta name="twitter:description" content="First note that the exponent in  p_{vec{X}}(vec{u}) is a quadratic form in all the u_{j}  terms, making this joint" />
<meta name="twitter:title" content="Let the components of the random vector X be jointly Gaussian, which means that the probability density function can be written as pX (u) = 1 / (2 π)^n/2 |K|^1/2 exp (- 1/2 (u – μ)^T K^-1 (u - μ) in which μ is a vector of constants; K is a square, symmetric, positive-definite matrix of constants;[solved!] | Vlavar Engineering" />

<meta property="article:published_time" content="2022-12-03T11:19:19+04:00" />
        <meta property="og:url" content="https://vlavar.com/engineeringdb/let-the-components-of-the-random-vector-x-be-jointly-gaussian-which-means-that-the-probability-density-function-can-be-written-as-px-u-1-2-%CF%80n-2-k1-2-exp-1-2-u-%CE%BCt" />
        <meta property="article:author" content="admin@vlavar" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:site" content="admin@vlavar" />
        <meta name="twitter:creator" content="admin@vlavar" />
     
    </head>
    
    <body>
        <nav id="desktop" class="desktop">
            <div id="desktop-container" class="container">
                <h1 id="logo"><a href="/">Vlavar</a></h1>
                <div id="desktop-menu" class="menu">
                    <a href="/">Home</a>
                    <a id="search">Search</a>
                    <a href="/tour/1">Tour</a>
                    <a href="/contact-us">Contact Us</a>
                </div>
                <button id="burger-button" class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
    
            </div>
        </nav>
        <nav id="mobile-navbar" class="mobile-nav">
            <div class="one text-fade"><a class="nav-link" href="/">Home</a></div>
            <div class="two text-fade"><a class="nav-link" id="search-mobile">Search</a></div>
            <div class="three text-fade"><a class="nav-link" href="/tour/1">Tour</a></div>
            <div class="four text-fade"><a class="nav-link" href="/contact-us">COntact Us</a></div>
        </nav>
    
        <div id="container" class="container-items tour">
            <div id="searchbox" class="searchbox">
                <div class="search">
                    <div class="icon"></div>
                    <form class="form">
                        <div class="input">
                        <input type="text" id="x" placeholder="Find solutions to engineering problems " autocomplete="off" >

                        </div>
                    </form>
                </div>
            </div>
            <div class="items question-block"> <span class="question">Guest Question. </span>
            <p class="blog">Let the components of the random vector <span class="tex-text">\(\vec{X}\)</span> be jointly Gaussian, which means that the probability density function can be written as</p> <span class="tex-text">\( p_{\vec{X}}(\vec{u})=\frac{1}{(2\pi)^{n/2}\left|K\right|^{1/2}}\exp (-\frac{1}{2}(\vec{u} - \vec{\mu })^{T} K^{-1} (\vec{u} - \vec{\mu }) ) \)</span> <p class="blog">in which <span class="tex-text">\( \vec{\mu }\)</span> is a vector of constants; <span class="tex-text">\( K\)</span> is a square, symmetric, positive-definite matrix of constants; and <span class="tex-text">\( K^{-1}\)</span> and <span class="tex-text">\( \left|K\right| \)</span> denote the inverse and determinant, respectively, of <span class="tex-text">\( \vec{X} \)</span> . Show that any subset of the components of <span class="tex-text">\( K\)</span> also is jointly Gaussian.</p>      
    <!-- end -->
            </div>
    
            <div class="items blog-solution">
                <div class="admin"><span>Admin</span> <svg class="verified-badge" xmlns="http://www.w3.org/2000/svg"
                        version="1.1" viewBox="0,0,24,24">
                        <path
                            d="M22.5 12.5c0-1.58-.875-2.95-2.148-3.6.154-.435.238-.905.238-1.4 0-2.21-1.71-3.998-3.818-3.998-.47 0-.92.084-1.336.25C14.818 2.415 13.51 1.5 12 1.5s-2.816.917-3.437 2.25c-.415-.165-.866-.25-1.336-.25-2.11 0-3.818 1.79-3.818 4 0 .494.083.964.237 1.4-1.272.65-2.147 2.018-2.147 3.6 0 1.495.782 2.798 1.942 3.486-.02.17-.032.34-.032.514 0 2.21 1.708 4 3.818 4 .47 0 .92-.086 1.335-.25.62 1.334 1.926 2.25 3.437 2.25 1.512 0 2.818-.916 3.437-2.25.415.163.865.248 1.336.248 2.11 0 3.818-1.79 3.818-4 0-.174-.012-.344-.033-.513 1.158-.687 1.943-1.99 1.943-3.484zm-6.616-3.334l-4.334 6.5c-.145.217-.382.334-.625.334-.143 0-.288-.04-.416-.126l-.115-.094-2.415-2.415c-.293-.293-.293-.768 0-1.06s.768-.294 1.06 0l1.77 1.767 3.825-5.74c.23-.345.696-.436 1.04-.207.346.23.44.696.21 1.04z"
                            fill="#1da1f2" />
                    </svg> </div>
    
                <div class="solution">Solution</div>
    
            </div>
    
            <div class="items answer-block">
                <p class="blog">
First note that the exponent in <span class="tex-text">\( p_{\vec{X}}(\vec{u})\)</span> is a quadratic form in all the <span class="tex-text">\(u_{j} \)</span> terms, making this joint distribution consistent with the scalar Gaussian distribution investigated in  and 2.8 the probability density function is a constant multiplying an exponential of a quadratic form. It can be shown that any joint probability density function meeting this condition can be written in the standard form given here.</p>
 <p class="blog">
Next let us find the probability density function of components <span class="tex-text">\(X_{1}\)</span> to <span class="tex-text">\(X_{n-1}\)</span>. To do this we need to integrate <span class="tex-text">\( p_{\vec{X}}(\vec{u})\)</span> over all possible values of <span class="tex-text">\(X_{n}\)</span>. This integration will be easier if we first rearrange the exponent in <span class="tex-text">\( p_{\vec{X}}(\vec{u})\)</span> as follows</p>
 <span class="tex-text">\(-\frac{1}{2}(\vec{u} &#8211; \vec{\mu })^{T} K^{-1}(\vec{u} &#8211; \vec{\mu })\equiv -\frac{1}{2} \sum\limits_{j=1}^{n}{\sum\limits_{k=1}^{n}{K_{jk}^{-1}(u_{j}-\mu _{j})(u_{k}-\mu _{k})} } = -\frac{K_{nn}^{-1}}{2} (u_{n}-\mu _{n})^{2}-(u_{n}-\mu _{n})\sum\limits_{k=1}^{n-1}{K_{jn}^{-1} (u_{j}-\mu _{j})} &#8211; \frac{1}{2} \sum\limits_{j=1}^{n-1}{\sum\limits_{k=1}^{n-1}{K_{jk}^{-1}(u_{j}-\mu _{j})(u_{k}-\mu _{k})} }\)</span> <p class="blog">
in which the symmetry of <span class="tex-text">\(K^{-1}\)</span> (which follows from the symmetry of <span class="tex-text">\(K\)</span>) has been used to simplify the terms that are linear in <span class="tex-text">\( (u_{n}-\mu _{n}) \)</span>. Note that <span class="tex-text">\( K_{nn}^{-1} \)</span> (as well as each of the other <span class="tex-text">\( K_{jj}^{-1} \)</span>terms) must be greater than zero so that the probability density function has a finite integral. Now one can use</p>
 <span class="tex-text">\(\sigma =\frac{1}{K_{nn}^{-1/2}} , \mu =\mu _{n} &#8211; \frac{1}{K_{nn}^{-1}}\sum\limits_{k=1}^{n-1}{(u_{j}-\mu _{j})}\)</span> <p class="blog">
and rewrite the exponent as</p>
 <span class="tex-text">\(-\frac{1}{2}(\vec{u} &#8211; \vec{\mu })^{T} K^{-1}(\vec{u} &#8211; \vec{\mu }) = -\frac{1}{2} (\frac{u_{n} &#8211; \mu }{\sigma })^{2} + \frac{1}{2\sigma ^{2}} ( \sum\limits_{k=1}^{n-1}{K_{jk}^{-1}(u_{j}-\mu _{j}))^{2}} &#8211; \frac{1}{2} \sum\limits_{j=1}^{n-1}{\sum\limits_{k=1}^{n-1}{K_{jk}^{-1}(u_{j}-\mu _{j})(u_{k}-\mu _{k})} }\)</span> <p class="blog">
This separation of the terms depending on u n from the other terms allows the desired probability density function to be written as</p>
 <span class="tex-text">\( p_{X_{1} &#8230; X_{n-1}} (u_{1},&#8230;,u_{n-1})=C\int_{-\infty }^{\infty }{\exp (-\frac{1}{2} [\frac{u_{n}-\mu }{\sigma } ]^{2} )du_{n}} =C(2\pi )^{1/2}\sigma \)</span> <p class="blog">
in which the value of the integral has been determined by observation from comparison with the probability density function of . Substituting for the term C then give</p>
 <span class="tex-text">\( p_{X_{1}&#8230; X_{n-1}} (u_{1},&#8230;,u_{n-1})=\frac{(2\pi )^{1/2}\sigma }{(2\pi )^{n/2} \sqrt{\left|K\right| } } \exp [\frac{1}{2\sigma ^{2}}(\sum\limits_{k=1}^{n-1}{K_{jn}^{-1}}(u_{j}-\mu _{j}) )^{2} &#8211; \frac{1}{2}\sum\limits_{j=1}^{n-1}{\sum\limits_{k=1}^{n-1}{K_{jn}^{-1}}(u_{j}-\mu _{j})(u_{k}-\mu _{k}) } ] \)</span> <p class="blog">
Note that the exponent in this probability density function is a quadratic form in all the <span class="tex-text">\(u_{j} \)</span> terms for <span class="tex-text">\(j=1,…,n-1 \)</span>. This is sufficient, without further simplification, to demonstrate that <span class="tex-text">\(p_{X_{1}&#8230;X_{n-1}} (u_{1},…,u_{n-1} \)</span> is a jointly Gaussian distribution. This procedure can be extended to show that if <span class="tex-text">\(X_{1} \)</span> to <span class="tex-text">\(X_{n} \)</span>, are jointly Gaussian, then any subset of those random variables is also jointly Gaussian, including the limiting case that each individual random variable in the set is Gaussian. This is a very important property of Gaussian distributions.</p>
 
    
          <!-- end -->
            </div>
        </div>
    
    
        <footer class="footer-bg footer-slct">
            <div class="footer-top">
                <a href="/tos">terms</a>
                <a href="/privacy">privacy</a>
                <a href="/contact-us">contact us</a>
            </div>
            <div class="footer-bottom">
                &copy; 2022 Vlavar Inc. All Rights Reserved.
            </div>
        </footer>    
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
        <script src="/assets/js/min/client-ui.js"></script>
    </body>
    
    </html>